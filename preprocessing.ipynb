{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd1f4b-8bb0-4daa-9bd8-2cf19e530000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_date, year, month, dayofmonth, dayofweek, hour\n",
    "from pyspark.sql.functions import round, count, mean, min, max, stddev, countDistinct, col, when, datediff, desc, avg\n",
    "from pyspark.sql import Window\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af95a9-7fe2-48c7-8617-adcb9e4b5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DivvyBikes_Preprocessing\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.minPartitionSize\", \"64m\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"50m\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"256m\") \\\n",
    "    .config(\"spark.kryoserializer.buffer\", \"64m\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC -XX:+UseCompressedOops -XX:+UseStringDeduplication\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC -XX:+UseCompressedOops\") \\\n",
    "    .config(\"spark.network.timeout\", \"800s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
    "    .config(\"spark.locality.wait\", \"0\") \\\n",
    "    .config(\"spark.sql.parquet.compression.codec\", \"snappy\") \\\n",
    "    .config(\"spark.sql.orc.compression.codec\", \"snappy\") \\\n",
    "    .config(\"spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version\", \"2\") \\\n",
    "    .config(\"spark.hadoop.parquet.enable.summary-metadata\", \"false\") \\\n",
    "    .config(\"spark.sql.parquet.mergeSchema\", \"false\") \\\n",
    "    .config(\"spark.sql.parquet.filterPushdown\", \"true\") \\\n",
    "    .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3b250-6196-4b3b-a356-47ac2529eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"ride_id\", StringType(), True),\n",
    "    StructField(\"rideable_type\", StringType(), True),\n",
    "    StructField(\"started_at\", TimestampType(), True),\n",
    "    StructField(\"ended_at\", TimestampType(), True),\n",
    "    StructField(\"start_station_name\", StringType(), True),\n",
    "    StructField(\"start_station_id\", StringType(), True),\n",
    "    StructField(\"end_station_name\", StringType(), True),\n",
    "    StructField(\"end_station_id\", StringType(), True),\n",
    "    StructField(\"start_lat\", DoubleType(), True),\n",
    "    StructField(\"start_lng\", DoubleType(), True),\n",
    "    StructField(\"end_lat\", DoubleType(), True),\n",
    "    StructField(\"end_lng\", DoubleType(), True),\n",
    "    StructField(\"member_casual\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Загружаем данные\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"timestampFormat\", \"yyyy-MM-dd HH:mm:ss\") \\\n",
    "    .option(\"encoding\", \"UTF-8\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"output.csv\")\n",
    "df_with_features = df.withColumn(\"ride_date\", to_date(col(\"started_at\"))) \\\n",
    "    .withColumn(\"ride_year\", year(col(\"started_at\"))) \\\n",
    "    .withColumn(\"ride_month\", month(col(\"started_at\"))) \\\n",
    "    .withColumn(\"ride_day\", dayofmonth(col(\"started_at\"))) \\\n",
    "    .withColumn(\"ride_dayofweek\", dayofweek(col(\"started_at\"))) \\\n",
    "    .withColumn(\"ride_hour\", hour(col(\"started_at\"))) \\\n",
    "    .withColumn(\"ride_duration_seconds\", \n",
    "               (col(\"ended_at\").cast(\"long\") - col(\"started_at\").cast(\"long\"))) \\\n",
    "    .withColumn(\"ride_duration_minutes\", \n",
    "               (col(\"ended_at\").cast(\"long\") - col(\"started_at\").cast(\"long\")) / 60.0)\n",
    "\n",
    "# Функция для расчета расстояния (формула Гаверсинуса)\n",
    "from pyspark.sql.functions import radians, sin, cos, atan2, sqrt, asin, lit\n",
    "\n",
    "# Используем встроенные функции Spark вместо Python UDF\n",
    "def haversine_distance_spark(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Расчет расстояния с использованием функций Spark\"\"\"\n",
    "    R = 6371  # Радиус Земли в км\n",
    "    \n",
    "    lat1_rad = radians(lat1)\n",
    "    lon1_rad = radians(lon1)\n",
    "    lat2_rad = radians(lat2)\n",
    "    lon2_rad = radians(lon2)\n",
    "    \n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    a = sin(dlat/2) ** 2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "# Используем функцию напрямую без UDF\n",
    "df_with_geo_features = df_with_features \\\n",
    "    .withColumn(\"distance_km\", haversine_distance_spark(\n",
    "        col(\"start_lat\"), col(\"start_lng\"), col(\"end_lat\"), col(\"end_lng\")))\\\n",
    "    .withColumn(\"lat_grid\", round(col(\"start_lat\"), 2)) \\\n",
    "    .withColumn(\"lng_grid\", round(col(\"start_lng\"), 2)) \\\n",
    "    .withColumn(\"is_weekend\", \n",
    "                when((col(\"ride_dayofweek\") == 1) | \n",
    "                     (col(\"ride_dayofweek\") == 7), True).otherwise(False)) \\\n",
    "    .withColumn(\"lat_diff\", abs(col(\"end_lat\") - col(\"start_lat\"))) \\\n",
    "    .withColumn(\"lng_diff\", abs(col(\"end_lng\") - col(\"start_lng\"))) \\\n",
    "    .withColumn(\"coord_diff\", col(\"lat_diff\") + col(\"lng_diff\")) \\\n",
    "    .withColumn(\"same_station\", \n",
    "                when(col(\"start_station_name\") == col(\"end_station_name\"), True).otherwise(False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc503d0-cf64-41c9-965e-7d015e82503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пробуем упрощенный подход без проверки скорости\n",
    "filtered_simple = df_with_geo_features.filter(\n",
    "    # 1. Базовая валидация\n",
    "    (col(\"ride_id\").isNotNull()) &\n",
    "    (col(\"started_at\").isNotNull()) &\n",
    "    (col(\"ended_at\").isNotNull()) &\n",
    "    (col(\"member_casual\").isNotNull()) &\n",
    "    (col(\"rideable_type\").isNotNull()) &\n",
    "    \n",
    "    # 2. Даты\n",
    "    (col(\"ended_at\") > col(\"started_at\")) &\n",
    "    \n",
    "    # 3. Длительность\n",
    "    (col(\"ride_duration_minutes\") >= 0) &\n",
    "    (col(\"ride_duration_minutes\") <= 1440) &\n",
    "    \n",
    "    # 4. Координаты\n",
    "    (col(\"start_lat\").between(41.6, 42.1)) &\n",
    "    (col(\"start_lng\").between(-87.95, -87.5)) &\n",
    "    (col(\"end_lat\").between(41.6, 42.1)) &\n",
    "    (col(\"end_lng\").between(-87.95, -87.5)) &\n",
    "    \n",
    "    # 5. Не нулевые координаты\n",
    "    (col(\"start_lat\") != 0) &\n",
    "    (col(\"start_lng\") != 0) &\n",
    "    \n",
    "    # 6. Не тестовые станции\n",
    "    (~lower(col(\"start_station_name\")).contains(\"test\")) &\n",
    "    (~lower(col(\"start_station_name\")).contains(\"hubbard\")) &\n",
    "    (~lower(col(\"start_station_name\")).contains(\"watson\"))\n",
    ")\n",
    "\n",
    "# Удаляем дубликаты\n",
    "filtered_simple = filtered_simple.dropDuplicates([\"ride_id\"])\n",
    "\n",
    "# Используем этот DataFrame для дальнейшей работы\n",
    "filtered_df = filtered_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ada86-7140-476b-bbc6-aa6065dd0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.withColumn(\n",
    "    \"start_geo_hash\", \n",
    "    concat(round(col(\"start_lat\"), 3).cast(\"string\"), lit(\"_\"), round(col(\"start_lng\"), 3).cast(\"string\"))\n",
    ").withColumn(\n",
    "    \"end_geo_hash\", \n",
    "    concat(round(col(\"end_lat\"), 3).cast(\"string\"), lit(\"_\"), round(col(\"end_lng\"), 3).cast(\"string\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb30b0-5ca7-494a-9ce9-653c7a28d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для заполнения пропущенных станций\n",
    "def fill_missing_stations(df, station_col, geo_hash_col):\n",
    "    \"\"\"Заполняет пропущенные названия станций наиболее частыми в той же геозоне\"\"\"\n",
    "    \n",
    "    # Создаем оконную функцию для нахождения наиболее частой станции в геозоне\n",
    "    window_spec = Window.partitionBy(geo_hash_col).orderBy(desc(\"count\"))\n",
    "    \n",
    "    # Создаем DataFrame с наиболее частыми станциями\n",
    "    common_stations = df.filter(col(station_col).isNotNull()) \\\n",
    "        .groupBy(geo_hash_col, station_col) \\\n",
    "        .agg(count(\"*\").alias(\"count\")) \\\n",
    "        .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "        .filter(col(\"rank\") == 1) \\\n",
    "        .select(geo_hash_col, col(station_col).alias(f\"common_{station_col}\"))\n",
    "    \n",
    "    # Присоединяем наиболее частые станции\n",
    "    df_filled = df.join(common_stations, on=geo_hash_col, how=\"left\") \\\n",
    "        .withColumn(f\"{station_col}_clean\", \n",
    "                   coalesce(col(station_col), col(f\"common_{station_col}\"))) \\\n",
    "        .drop(f\"common_{station_col}\")\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "# Заполняем пропущенные стартовые станции\n",
    "filtered_df = fill_missing_stations(filtered_df, \"start_station_name\", \"start_geo_hash\")\n",
    "\n",
    "# Заполняем пропущенные конечные станции\n",
    "filtered_df = fill_missing_stations(filtered_df, \"end_station_name\", \"end_geo_hash\")\n",
    "\n",
    "# Заменяем оригинальные колонки очищенными\n",
    "filtered_df = filtered_df \\\n",
    "    .drop(\"start_station_name\", \"end_station_name\") \\\n",
    "    .withColumnRenamed(\"start_station_name_clean\", \"start_station_name\") \\\n",
    "    .withColumnRenamed(\"end_station_name_clean\", \"end_station_name\") \\\n",
    "    .drop(\"start_geo_hash\", \"end_geo_hash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872aefb-fa73-4ddf-9d2a-e56e2a6a2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Удаляем поездки с экстремально малым расстоянием при большой длительности\n",
    "filtered_df = filtered_df.filter(\n",
    "    ~((col(\"distance_km\") < 0.01) & (col(\"ride_duration_minutes\") > 40))\n",
    ")\n",
    "\n",
    "# 2. Фильтр для поездок на ту же станцию с аномальной длительностью\n",
    "filtered_df = filtered_df.filter(\n",
    "    ~(\n",
    "        (col(\"start_station_name\") == col(\"end_station_name\")) &\n",
    "        (col(\"ride_duration_minutes\") > 1440)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Удаляем поездки с нереальной скоростью\n",
    "filtered_df = filtered_df.withColumn(\n",
    "    \"speed_kmh\",\n",
    "    when(col(\"ride_duration_minutes\") > 0,\n",
    "         col(\"distance_km\") / (col(\"ride_duration_minutes\") / 60.0)).otherwise(0)\n",
    ")\n",
    "\n",
    "filtered_df = filtered_df.filter(\n",
    "    (col(\"speed_kmh\") <= 45) | (col(\"speed_kmh\").isNull())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1ffc1-b189-40b0-aeda-3fd9fdd6bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_with_features = filtered_df \\\n",
    "    .withColumn(\"lat_grid\", round(col(\"start_lat\"), 2)) \\\n",
    "    .withColumn(\"lng_grid\", round(col(\"start_lng\"), 2)) \\\n",
    "    .withColumn(\"is_weekend\", \n",
    "                when((col(\"ride_dayofweek\") == 1) | \n",
    "                     (col(\"ride_dayofweek\") == 7), True).otherwise(False)) \\\n",
    "    .withColumn(\"lat_diff\", abs(col(\"end_lat\") - col(\"start_lat\"))) \\\n",
    "    .withColumn(\"lng_diff\", abs(col(\"end_lng\") - col(\"start_lng\"))) \\\n",
    "    .withColumn(\"coord_diff\", col(\"lat_diff\") + col(\"lng_diff\")) \\\n",
    "    .withColumn(\"speed_kmh\", \n",
    "                when(col(\"ride_duration_minutes\") > 0, \n",
    "                     col(\"distance_km\") / (col(\"ride_duration_minutes\") / 60.0)).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765e527-8bb0-4252-bb6a-0239a6ac6e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412cef2-b515-4b08-a85d-c1c07771d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Общая статистика\n",
    "print(\"\\n1. ОБЩАЯ СТАТИСТИКА:\")\n",
    "cleaned_df_with_features.select(\n",
    "    count(\"*\").alias(\"Всего_записей\"),\n",
    "    round(mean(\"ride_duration_minutes\"), 2).alias(\"Ср_длит_мин\"),\n",
    "    round(min(\"ride_duration_minutes\"), 2).alias(\"Мин_длит\"),\n",
    "    round(max(\"ride_duration_minutes\"), 2).alias(\"Макс_длит\"),\n",
    "    round(mean(\"distance_km\"), 3).alias(\"Ср_расст_км\"),\n",
    "    round(max(\"distance_km\"), 3).alias(\"Макс_расст_км\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80248911-c4ee-4a10-bb96-509846ebcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. СТАТИСТИКА ПО ПОЛЬЗОВАТЕЛЯМ (member_casual):\")\n",
    "cleaned_df_with_features.groupBy(\"member_casual\").agg(\n",
    "    count(\"*\").alias(\"Поездок\"),\n",
    "    round(count(\"*\") * 100.0 / cleaned_df_with_features.count(), 1).alias(\"Доля_%\"),\n",
    "    round(mean(\"ride_duration_minutes\"), 1).alias(\"Ср_длит_мин\"),\n",
    "    round(mean(\"distance_km\"), 2).alias(\"Ср_расст_км\")\n",
    ").orderBy(desc(\"Поездок\")).show()\n",
    "\n",
    "# 3. Статистика по типам велосипедов\n",
    "print(\"\\n3. СТАТИСТИКА ПО ТИПАМ ВЕЛОСИПЕДОВ (rideable_type):\")\n",
    "cleaned_df_with_features.groupBy(\"rideable_type\").agg(\n",
    "    count(\"*\").alias(\"Поездок\"),\n",
    "    round(count(\"*\") * 100.0 / cleaned_df_with_features.count(), 1).alias(\"Доля_%\"),\n",
    "    round(mean(\"ride_duration_minutes\"), 1).alias(\"Ср_длит_мин\"),\n",
    "    round(mean(\"distance_km\"), 2).alias(\"Ср_расст_км\")\n",
    ").orderBy(desc(\"Поездок\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa73cb-8284-433f-b4ac-aecb5f5a5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4. СТАТИСТИКА ПО ДНЯМ НЕДЕЛИ:\")\n",
    "cleaned_df_with_features.groupBy(\"ride_dayofweek\").agg(\n",
    "    count(\"*\").alias(\"Поездок\"),\n",
    "    round(count(\"*\") * 100.0 / cleaned_df_with_features.count(), 1).alias(\"Доля_%\"),\n",
    "    round(mean(\"ride_duration_minutes\"), 1).alias(\"Ср_длит_мин\"),\n",
    "    round(mean(\"distance_km\"), 2).alias(\"Ср_расст_км\")\n",
    ").orderBy(\"ride_dayofweek\").show(7)\n",
    "\n",
    "# 5. Статистика по часам\n",
    "print(\"\\n5. СТАТИСТИКА ПО ЧАСАМ СУТОК:\")\n",
    "cleaned_df_with_features.groupBy(\"ride_hour\").agg(\n",
    "    count(\"*\").alias(\"Поездок\"),\n",
    "    round(count(\"*\") * 100.0 / cleaned_df_with_features.count(), 1).alias(\"Доля_%\"),\n",
    "    round(mean(\"ride_duration_minutes\"), 1).alias(\"Ср_длит_мин\")\n",
    ").orderBy(\"ride_hour\").show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04591be5-5b3c-41f4-8e41-456c8d733f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Описательная статистика\n",
    "print(\"\\n6. ОПИСАТЕЛЬНАЯ СТАТИСТИКА (describe):\")\n",
    "cleaned_df_with_features.select(\n",
    "    \"ride_duration_minutes\", \"distance_km\", \"speed_kmh\"\n",
    ").describe().show()\n",
    "\n",
    "# 7. Квантили распределения\n",
    "print(\"\\n7. КВАНТИЛИ РАСПРЕДЕЛЕНИЯ ДЛИТЕЛЬНОСТИ:\")\n",
    "quantiles = cleaned_df_with_features.approxQuantile(\n",
    "    \"ride_duration_minutes\", \n",
    "    [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99], \n",
    "    0.01\n",
    ")\n",
    "\n",
    "# Создаем DataFrame для квантилей\n",
    "from pyspark.sql import Row\n",
    "quantile_data = [(f\"{p*100:.0f}%\", v) for p, v in zip(\n",
    "    [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99], \n",
    "    quantiles\n",
    ")]\n",
    "\n",
    "quantile_df = spark.createDataFrame(\n",
    "    [Row(Квантиль=k, Длительность_мин=v) for k, v in quantile_data]\n",
    ")\n",
    "quantile_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f97ac-52eb-4ec1-a932-abba87ddd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Географическая статистика\n",
    "print(\"\\n8. ГЕОГРАФИЧЕСКАЯ СТАТИСТИКА:\")\n",
    "cleaned_df_with_features.select(\n",
    "    round(min(\"start_lat\"), 4).alias(\"Мин_широта\"),\n",
    "    round(max(\"start_lat\"), 4).alias(\"Макс_широта\"),\n",
    "    round(mean(\"start_lat\"), 4).alias(\"Ср_широта\"),\n",
    "    round(min(\"start_lng\"), 4).alias(\"Мин_долгота\"),\n",
    "    round(max(\"start_lng\"), 4).alias(\"Макс_долгота\"),\n",
    "    round(mean(\"start_lng\"), 4).alias(\"Ср_долгота\"),\n",
    "    countDistinct(\"start_station_name\").alias(\"Уник_старт_станций\"),\n",
    "    countDistinct(\"end_station_name\").alias(\"Уник_конеч_станций\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cdf58-913c-4a36-8156-f71c15a4fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Статистика по скорости\n",
    "print(\"\\n9. СТАТИСТИКА ПО СКОРОСТИ:\")\n",
    "cleaned_df_with_features.select(\n",
    "    round(mean(\"speed_kmh\"), 1).alias(\"Ср_скорость_кмч\"),\n",
    "    round(stddev(\"speed_kmh\"), 1).alias(\"Стд_отклонение\"),\n",
    "    round(min(\"speed_kmh\"), 1).alias(\"Мин_скорость\"),\n",
    "    round(max(\"speed_kmh\"), 1).alias(\"Макс_скорость\"),\n",
    "    count(when(col(\"speed_kmh\") > 25, True)).alias(\"Поездок_25кмч\"),\n",
    "    count(when(col(\"speed_kmh\") > 30, True)).alias(\"Поездок_30кмч\")\n",
    ").show()\n",
    "\n",
    "# 10. Статистика по возвратам на станцию\n",
    "print(\"\\n10. СТАТИСТИКА ПО ВОЗВРАТАМ:\")\n",
    "cleaned_df_with_features.select(\n",
    "    round(mean(when(col(\"same_station\") == True, 1).otherwise(0)) * 100, 1).alias(\"Процент_возвратов_%\"),\n",
    "    round(mean(when(col(\"same_station\") == True, col(\"ride_duration_minutes\"))), 1).alias(\"Ср_длит_возврат_мин\"),\n",
    "    round(mean(when(col(\"same_station\") == False, col(\"ride_duration_minutes\"))), 1).alias(\"Ср_длит_перемещение_мин\"),\n",
    "    round(mean(when(col(\"same_station\") == True, col(\"distance_km\"))), 2).alias(\"Ср_расст_возврат_км\"),\n",
    "    round(mean(when(col(\"same_station\") == False, col(\"distance_km\"))), 2).alias(\"Ср_расст_перемещение_км\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113cb21-0314-4a70-8f7f-916ab1252f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Временной диапазон\n",
    "print(\"\\n11. ВРЕМЕННОЙ ДИАПАЗОН ДАННЫХ:\")\n",
    "cleaned_df_with_features.select(\n",
    "    min(\"started_at\").alias(\"Первая_поездка\"),\n",
    "    max(\"started_at\").alias(\"Последняя_поездка\"),\n",
    "    datediff(max(\"started_at\"), min(\"started_at\")).alias(\"Дней_в_данных\"),\n",
    "    countDistinct(\"ride_date\").alias(\"Уник_дней\")\n",
    ").show()\n",
    "\n",
    "# 12. Топ-10 популярных стартовых станций\n",
    "print(\"\\n12. ТОП-10 ПОПУЛЯРНЫХ СТАРТОВЫХ СТАНЦИЙ:\")\n",
    "cleaned_df_with_features.groupBy(\"start_station_name\").agg(\n",
    "    count(\"*\").alias(\"Поездок\"),\n",
    "    round(mean(\"ride_duration_minutes\"), 1).alias(\"Ср_длит_мин\"),\n",
    "    round(mean(\"distance_km\"), 2).alias(\"Ср_расст_км\")\n",
    ").orderBy(desc(\"Поездок\")).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21eea8-f0ee-4051-889a-0d0b6c2b0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_with_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bae48d-66c8-4967-b507-5d1d5fa5254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05611c2-a0d6-4540-a8c2-a29838d37809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
